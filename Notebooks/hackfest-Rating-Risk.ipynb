{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "\n",
    "def get_stock_ratings(ticker_symbols):\n",
    "    \"\"\"\n",
    "    Generate risk assessments and ratings for multiple ticker symbols.\n",
    "    \n",
    "    Args:\n",
    "        ticker_symbols (list): List of ticker symbols (e.g., [\"AAPL\", \"MSFT\"])\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with ticker symbols as keys and their risk/rating assessments\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    seq_length = 30\n",
    "    prediction_days = 60  # For forward-looking assessment\n",
    "    \n",
    "    # Load the trained model and scaler for future predictions\n",
    "    try:\n",
    "        model = BiLSTMModel().to(device)\n",
    "        model.load_state_dict(torch.load('bilstm_model.pth', map_location=device))\n",
    "        model.eval()\n",
    "        scaler_diff = joblib.load('scaler.joblib')\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: {e}\")\n",
    "        # Continue without model predictions if loading fails\n",
    "        model = None\n",
    "        scaler_diff = None\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for ticker in ticker_symbols:\n",
    "        try:\n",
    "            # Get historical data\n",
    "            ticker_obj = yf.Ticker(ticker)\n",
    "            hist_data = ticker_obj.history(period=\"3y\", interval=\"1d\")  # 3 years of data for better analysis\n",
    "            \n",
    "            if hist_data.empty or len(hist_data) < 252:  # Need at least 1 year of data\n",
    "                results[ticker] = {\"error\": f\"Insufficient historical data for {ticker}\"}\n",
    "                continue\n",
    "                \n",
    "            # Extract close prices\n",
    "            close_prices = hist_data['Close'].values.astype(float)\n",
    "            \n",
    "            # ------- RISK CALCULATION -------\n",
    "            # Calculate daily returns\n",
    "            daily_returns = np.diff(close_prices) / close_prices[:-1]\n",
    "            \n",
    "            # Calculate annualized volatility (standard deviation of returns * sqrt(252))\n",
    "            volatility_annual = np.std(daily_returns) * np.sqrt(252) * 100  # as percentage\n",
    "            \n",
    "            # Determine risk level based on volatility\n",
    "            if volatility_annual < 20:  # Slightly more generous threshold\n",
    "                risk_level = \"low\"\n",
    "            elif volatility_annual < 35:  # Slightly more generous threshold\n",
    "                risk_level = \"medium\"\n",
    "            else:\n",
    "                risk_level = \"high\"\n",
    "            \n",
    "            # ------- RATING CALCULATION -------\n",
    "            # 1. Historical return (1-year): 30% weight (increased from 20%)\n",
    "            one_year_return = (close_prices[-1] / close_prices[-min(252, len(close_prices)-1)] - 1) * 100\n",
    "            \n",
    "            # 2. Recent momentum (6-month): 25% weight (increased from 15%)\n",
    "            six_month_return = (close_prices[-1] / close_prices[-min(126, len(close_prices)-1)] - 1) * 100\n",
    "            \n",
    "            # 3. Trend stability (3-month): 15% weight (unchanged)\n",
    "            # Calculate R-squared of a linear fit to the last 3 months of prices\n",
    "            recent_prices = close_prices[-min(63, len(close_prices)):]\n",
    "            x = np.arange(len(recent_prices))\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(x, recent_prices)\n",
    "            trend_stability = r_value ** 2\n",
    "            # If trend is positive, we can consider higher trend stability as better\n",
    "            trend_direction = 1 if slope > 0 else -1\n",
    "            \n",
    "            # 4. Risk-adjusted return (Sharpe Ratio): 20% weight (reduced from 30%)\n",
    "            # Assuming risk-free rate of 2%\n",
    "            risk_free_rate = 0.02\n",
    "            excess_return = (one_year_return / 100) - risk_free_rate\n",
    "            sharpe_ratio = (excess_return / (volatility_annual / 100)) if volatility_annual > 0 else 0\n",
    "            \n",
    "            # 5. Predicted future return (next 60 days): 10% weight (reduced from 20%)\n",
    "            # Use the existing model to predict future prices if available\n",
    "            future_return = 0\n",
    "            if model is not None and scaler_diff is not None:\n",
    "                try:\n",
    "                    # Prepare for prediction\n",
    "                    close_prices_array = hist_data['Close'].values.astype(float).reshape(-1, 1)\n",
    "                    diff_close_prices = np.diff(close_prices_array, axis=0)\n",
    "                    diff_scaled = scaler_diff.transform(diff_close_prices)\n",
    "                    \n",
    "                    # Get last sequence\n",
    "                    last_sequence = torch.tensor(diff_scaled[-seq_length:].reshape(1, seq_length, 1), dtype=torch.float32).to(device)\n",
    "                    \n",
    "                    # Predict future prices\n",
    "                    last_price = close_prices_array[-1][0]\n",
    "                    future_prices = [last_price]\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        current_sequence = last_sequence\n",
    "                        \n",
    "                        for _ in range(prediction_days):\n",
    "                            # Predict next difference\n",
    "                            pred_diff_scaled = model(current_sequence)\n",
    "                            pred_diff = scaler_diff.inverse_transform(pred_diff_scaled.cpu().numpy())[0][0]\n",
    "                            \n",
    "                            # Calculate next price\n",
    "                            next_price = future_prices[-1] + pred_diff\n",
    "                            future_prices.append(next_price)\n",
    "                            \n",
    "                            # Update sequence\n",
    "                            current_seq_np = current_sequence.cpu().numpy()\n",
    "                            current_seq_np = current_seq_np[:, 1:, :]\n",
    "                            pred_for_seq = pred_diff_scaled.cpu().numpy().reshape(1, 1, 1)\n",
    "                            new_sequence = np.concatenate([current_seq_np, pred_for_seq], axis=1)\n",
    "                            current_sequence = torch.tensor(new_sequence, dtype=torch.float32).to(device)\n",
    "                    \n",
    "                    # Calculate predicted return\n",
    "                    future_return = (future_prices[-1] / future_prices[0] - 1) * 100\n",
    "                except Exception as e:\n",
    "                    print(f\"Prediction failed for {ticker}: {e}\")\n",
    "                    # If model prediction fails, calculate momentum and extrapolate\n",
    "                    recent_slope = (close_prices[-1] - close_prices[-22]) / close_prices[-22] * 100  # ~1 month trend\n",
    "                    future_return = recent_slope * 2  # Simple extrapolation based on recent momentum\n",
    "            else:\n",
    "                # If model isn't available, use recent momentum as a proxy\n",
    "                recent_weeks = min(22, len(close_prices)-1)  # ~1 month of trading days\n",
    "                future_return = (close_prices[-1] / close_prices[-recent_weeks] - 1) * 100 * 2  # Extrapolated 2 months\n",
    "            \n",
    "            # ------- ENHANCED NORMALIZATION -------\n",
    "            # More generous normalization to better reward exceptional performance\n",
    "            \n",
    "            # 1. One-year return (higher range to properly score exceptional stocks like NVDA)\n",
    "            # Old: normalized_one_year = min(100, max(0, one_year_return + 20))  # -20% to 80% → 0 to 100\n",
    "            # New: Allow for recognizing returns up to 200%\n",
    "            normalized_one_year = min(100, max(0, (one_year_return / 2) + 50))  # -100% to 150% → 0 to 100\n",
    "            \n",
    "            # 2. Six-month return (higher range)\n",
    "            # Old: normalized_six_month = min(100, max(0, six_month_return * 2 + 20))  # -10% to 40% → 0 to 100\n",
    "            # New: Allow for recognizing higher returns\n",
    "            normalized_six_month = min(100, max(0, six_month_return + 50))  # -50% to 50% → 0 to 100\n",
    "            \n",
    "            # 3. Trend stability - now consider direction\n",
    "            # Upward trend is better than downward trend with same stability\n",
    "            normalized_trend = trend_stability * 100 * (1.5 if trend_direction > 0 else 0.5)  # 0 to 150 for positive, 0 to 50 for negative\n",
    "            normalized_trend = min(100, max(0, normalized_trend))  # Cap at 100\n",
    "            \n",
    "            # 4. Sharpe ratio (more generous scaling)\n",
    "            # Old: normalized_sharpe = min(100, max(0, sharpe_ratio * 25 + 50))  # -2 to 2 → 0 to 100\n",
    "            # New: Better recognize high Sharpe ratios\n",
    "            normalized_sharpe = min(100, max(0, sharpe_ratio * 15 + 40))  # -2.67 to 4 → 0 to 100\n",
    "            \n",
    "            # 5. Future return (more generous)\n",
    "            # Old: normalized_future = min(100, max(0, future_return * 5 + 20))  # -4% to 16% → 0 to 100\n",
    "            # New: Allow for higher projected returns\n",
    "            normalized_future = min(100, max(0, future_return * 3 + 40))  # -13.33% to 20% → 0 to 100\n",
    "            \n",
    "            # ------- ADJUSTED WEIGHTS -------\n",
    "            # Apply new weights (increased historical components, reduced future prediction)\n",
    "            # volatility_penalty = min(metrics['volatility_annual'] / 1000, 1.0)\n",
    "            # trend_penalty = -0.05 if metrics['trend_direction'] == 'negative' else 0\n",
    "            \n",
    "            weighted_score = (\n",
    "                normalized_one_year * 0.30 +\n",
    "                normalized_six_month * 0.25 +\n",
    "                normalized_trend * 0.10 +\n",
    "                normalized_sharpe * 0.30 +\n",
    "                normalized_future * 0.02  # drastically reduced        # small penalty for downtrend\n",
    "            )\n",
    "            \n",
    "            # ------- IMPROVED RATING SCALE -------\n",
    "            # Adjust thresholds to be more reasonable\n",
    "            if weighted_score >= 40:      # Was 80\n",
    "                rating = 5\n",
    "            elif weighted_score >= 30:    # Was 60\n",
    "                rating = 4\n",
    "            elif weighted_score >= 20:    # Was 40\n",
    "                rating = 3\n",
    "            elif weighted_score >= 10:    # Was 20\n",
    "                rating = 2\n",
    "            else:\n",
    "                rating = 1\n",
    "            \n",
    "            # Add company name and sector information if available\n",
    "            company_info = {}\n",
    "            try:\n",
    "                info = ticker_obj.info\n",
    "                company_info = {\n",
    "                    \"name\": info.get(\"shortName\", \"\"),\n",
    "                    \"sector\": info.get(\"sector\", \"\"),\n",
    "                    \"industry\": info.get(\"industry\", \"\")\n",
    "                }\n",
    "            except:\n",
    "                pass  # Skip if info retrieval fails\n",
    "            \n",
    "            # Store the results\n",
    "            results[ticker] = {\n",
    "                \"risk_level\": risk_level,\n",
    "                \"rating\": rating,\n",
    "                \"company_info\": company_info,\n",
    "                \"metrics\": {\n",
    "                    \"volatility_annual\": round(volatility_annual, 2),\n",
    "                    \"one_year_return\": round(one_year_return, 2),\n",
    "                    \"six_month_return\": round(six_month_return, 2),\n",
    "                    \"trend_stability\": round(trend_stability, 2),\n",
    "                    \"trend_direction\": \"positive\" if trend_direction > 0 else \"negative\",\n",
    "                    \"sharpe_ratio\": round(sharpe_ratio, 2),\n",
    "                    \"predicted_future_return\": round(future_return, 2),\n",
    "                    \"weighted_score\": round(weighted_score, 2)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            results[ticker] = {\"error\": f\"Failed to analyze {ticker}: {str(e)}\"}\n",
    "    \n",
    "    return results\n",
    "\n",
    "# BiLSTM Model definition (same as in previous code)\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=1):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "'''\n",
    "We need this function to lower ratings for risky stocks with extremely poor performance indicators.\n",
    "How we did this:\n",
    "We checked for high-risk stocks with very high volatility, negative trends, poor returns, and low stability, then reduced their ratings.\n",
    "\n",
    "How we got to know:\n",
    "We noticed some stocks (like IDEA) had unrealistic metrics and didn’t match their high rating, signaling the need for adjustment.\n",
    "'''\n",
    "\n",
    "def adjust_ratings(data):\n",
    "    for key, val in data.items():\n",
    "        if 'metrics' not in val or 'risk_level' not in val:\n",
    "            continue\n",
    "        metrics = val['metrics']\n",
    "        if (\n",
    "            val['risk_level'] == 'high' and\n",
    "            metrics.get('volatility_annual', 0) > 1000 and\n",
    "            metrics.get('sharpe_ratio', 1) <= 0 and\n",
    "            metrics.get('trend_direction') == 'negative' and\n",
    "            metrics.get('trend_stability', 1) < 0.3 and\n",
    "            metrics.get('one_year_return', 0) < 0\n",
    "        ):\n",
    "            val['rating'] = min(val['rating'], 2)\n",
    "    return data\n",
    "\n",
    "# usage  : data = adjust_ratings(get_stock_ratings(['AAPL','MSFT','NVDA','GOOG','IDEA'])) -> gives dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat = adjust_ratings(get_stock_ratings(['AAPL','MSFT','NVDA','GOOG','IDEA','META','AMZN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7042982,
     "sourceId": 11267194,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7043006,
     "sourceId": 11267224,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
